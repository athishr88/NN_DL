{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LA4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8eIU81Ylc6r5poX1qvTxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athishr88/NN_DL/blob/main/LA4/LA4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FhKAinViIEKd",
        "outputId": "f6bba27f-44cf-4b43-ed00-4dd757798dea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': 'https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/test.json',\n",
              " 'train': 'https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/train.json',\n",
              " 'val': 'https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/val.json'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "## Set up the VizWiz-VQA dataset\n",
        "\n",
        "img_dir = \"https://vizwiz.cs.colorado.edu//VizWiz_visualization_img/\"\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "dataset_files_dict = {}\n",
        "\n",
        "for split in splits:\n",
        "  annotation_file = \"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/%s.json\" %split\n",
        "  dataset_files_dict[split] = annotation_file\n",
        "\n",
        "dataset_files_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the files to extract train, test, val dataset with label (Only 20% of data will be used in this exercise)\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "fraction_of_data = 0.04\n",
        "\n",
        "def extract_dataset(split):\n",
        "  split_data = requests.get(dataset_files_dict[split], allow_redirects=True)\n",
        "  data_all = split_data.json()\n",
        "  random.shuffle(data_all)\n",
        "  data = data_all[:int(len(data_all)*fraction_of_data)]\n",
        "  data = pd.DataFrame(data)\n",
        "  return data\n",
        "\n",
        "train_data_raw = extract_dataset(\"train\")\n",
        "val_data_raw = extract_dataset(\"val\")\n",
        "test_data_raw = extract_dataset(\"test\")"
      ],
      "metadata": {
        "id": "hKpTuae-IIVW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize train_data_raw\n",
        "train_data_raw.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O6z1PL-ZIJeu",
        "outputId": "1881ee2e-5486-4c94-a30a-6b1737951b44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       image                                     question  \\\n",
              "0  VizWiz_train_00018154.jpg  That you very much. I really appreciate it.   \n",
              "1  VizWiz_train_00001855.jpg                       >Label on this bottle.   \n",
              "2  VizWiz_train_00000950.jpg                                What is this?   \n",
              "3  VizWiz_train_00009934.jpg                                What is this?   \n",
              "4  VizWiz_train_00007828.jpg       Can you tell me what this bottle says?   \n",
              "\n",
              "                                             answers   answer_type  answerable  \n",
              "0  [{'answer': 'unanswerable', 'answer_confidence...  unanswerable           0  \n",
              "1  [{'answer_confidence': 'yes', 'answer': 'machi...  unanswerable           0  \n",
              "2  [{'answer_confidence': 'yes', 'answer': 'unans...         other           1  \n",
              "3  [{'answer_confidence': 'no', 'answer': 'unsuit...         other           1  \n",
              "4  [{'answer_confidence': 'yes', 'answer': 'unsui...  unanswerable           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f1f5f10-61b2-4d05-9cd9-fa41daf3fca2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "      <th>answer_type</th>\n",
              "      <th>answerable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VizWiz_train_00018154.jpg</td>\n",
              "      <td>That you very much. I really appreciate it.</td>\n",
              "      <td>[{'answer': 'unanswerable', 'answer_confidence...</td>\n",
              "      <td>unanswerable</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VizWiz_train_00001855.jpg</td>\n",
              "      <td>&gt;Label on this bottle.</td>\n",
              "      <td>[{'answer_confidence': 'yes', 'answer': 'machi...</td>\n",
              "      <td>unanswerable</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VizWiz_train_00000950.jpg</td>\n",
              "      <td>What is this?</td>\n",
              "      <td>[{'answer_confidence': 'yes', 'answer': 'unans...</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VizWiz_train_00009934.jpg</td>\n",
              "      <td>What is this?</td>\n",
              "      <td>[{'answer_confidence': 'no', 'answer': 'unsuit...</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VizWiz_train_00007828.jpg</td>\n",
              "      <td>Can you tell me what this bottle says?</td>\n",
              "      <td>[{'answer_confidence': 'yes', 'answer': 'unsui...</td>\n",
              "      <td>unanswerable</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f1f5f10-61b2-4d05-9cd9-fa41daf3fca2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f1f5f10-61b2-4d05-9cd9-fa41daf3fca2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f1f5f10-61b2-4d05-9cd9-fa41daf3fca2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove small amount of unanswerable data (Class balancing)\n",
        "\n",
        "def balance_data(data):\n",
        "  data_answerable = data[data.answerable != 0]\n",
        "  data_unanswerable = data[data.answerable == 0]\n",
        "  data_unanswerable_sample = data_unanswerable.sample(frac=.1)\n",
        "\n",
        "  balanced_data = pd.concat([data_answerable, data_unanswerable_sample], ignore_index = True)\n",
        "  balanced_data.reset_index()\n",
        "  return balanced_data\n",
        "\n",
        "train_data_balanced = balance_data(train_data_raw)\n",
        "val_data_balanced = balance_data(val_data_raw)\n"
      ],
      "metadata": {
        "id": "u3xzNQVzINEu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create labels\n",
        "# Only the most frequent answer out of the 10 answers is considered as label\n",
        "\n",
        "def most_frequent(List):\n",
        "    return max(set(List), key = List.count)\n",
        "\n",
        "def generate_labels(df):\n",
        "  labels = []\n",
        "  gtlist = df[\"answers\"]\n",
        "\n",
        "  for answers in gtlist:\n",
        "    all_answers = []\n",
        "    for answer in answers:\n",
        "      all_answers.append(answer[\"answer\"])\n",
        "    labels.append(most_frequent(all_answers))\n",
        "  \n",
        "  labels_text = [x.split()[0] for x in labels]\n",
        "  df[\"label\"] = labels_text\n",
        "  \n",
        "  return df\n",
        "\n",
        "train_data_w_labels = generate_labels(train_data_balanced)\n",
        "val_data_w_labels = generate_labels(val_data_balanced)"
      ],
      "metadata": {
        "id": "GCOgVaeWIOVt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_w_labels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ynfY1XZ_eRLj",
        "outputId": "3c1a4e68-3d75-4b7a-83f8-65fd8bd21592"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       image                                       question  \\\n",
              "0  VizWiz_train_00000950.jpg                                  What is this?   \n",
              "1  VizWiz_train_00009934.jpg                                  What is this?   \n",
              "2  VizWiz_train_00009446.jpg                                  What is this?   \n",
              "3  VizWiz_train_00018054.jpg  What is the color of the sky in this picture?   \n",
              "4  VizWiz_train_00002123.jpg                                  What is this?   \n",
              "\n",
              "                                             answers answer_type  answerable  \\\n",
              "0  [{'answer_confidence': 'yes', 'answer': 'unans...       other           1   \n",
              "1  [{'answer_confidence': 'no', 'answer': 'unsuit...       other           1   \n",
              "2  [{'answer_confidence': 'yes', 'answer': 'gerg'...       other           1   \n",
              "3  [{'answer_confidence': 'yes', 'answer': 'blue'...       other           1   \n",
              "4  [{'answer_confidence': 'yes', 'answer': 'pepsi...       other           1   \n",
              "\n",
              "          label  \n",
              "0  unanswerable  \n",
              "1        tissue  \n",
              "2       raisins  \n",
              "3          blue  \n",
              "4         pepsi  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca333d15-3617-4c79-81f1-3228e65a710c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "      <th>answer_type</th>\n",
              "      <th>answerable</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VizWiz_train_00000950.jpg</td>\n",
              "      <td>What is this?</td>\n",
              "      <td>[{'answer_confidence': 'yes', 'answer': 'unans...</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "      <td>unanswerable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VizWiz_train_00009934.jpg</td>\n",
              "      <td>What is this?</td>\n",
              "      <td>[{'answer_confidence': 'no', 'answer': 'unsuit...</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "      <td>tissue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VizWiz_train_00009446.jpg</td>\n",
              "      <td>What is this?</td>\n",
              "      <td>[{'answer_confidence': 'yes', 'answer': 'gerg'...</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "      <td>raisins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VizWiz_train_00018054.jpg</td>\n",
              "      <td>What is the color of the sky in this picture?</td>\n",
              "      <td>[{'answer_confidence': 'yes', 'answer': 'blue'...</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "      <td>blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VizWiz_train_00002123.jpg</td>\n",
              "      <td>What is this?</td>\n",
              "      <td>[{'answer_confidence': 'yes', 'answer': 'pepsi...</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "      <td>pepsi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca333d15-3617-4c79-81f1-3228e65a710c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca333d15-3617-4c79-81f1-3228e65a710c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca333d15-3617-4c79-81f1-3228e65a710c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modulizing\n",
        "\n",
        "train_images = train_data_w_labels[\"image\"] \n",
        "train_questions = train_data_w_labels[\"question\"]\n",
        "train_labels_text = train_data_w_labels[\"label\"]\n",
        "\n",
        "val_images = val_data_w_labels[\"image\"] \n",
        "val_questions = val_data_w_labels[\"question\"]\n",
        "val_labels_text = val_data_w_labels[\"label\"]\n",
        "\n",
        "test_images = test_data_raw[\"image\"]\n",
        "test_questions = test_data_raw[\"question\"]\n",
        "\n",
        "print(len(train_images), len(train_labels_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "q8mHnSMmIPe1",
        "outputId": "e0dcb0f3-d844-4ac0-f17d-e5421a80e147"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "621 621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "None in test_questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lkcpbhOAefH-",
        "outputId": "91e04b59-d61f-46c3-e29b-de96ed567faf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many unique classes are there in training set\n",
        "print(\"Classes: \", len(np.unique(train_labels_text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rw3fHaE3IQkI",
        "outputId": "74a209b6-371f-4643-fc65-873e884ef3ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes:  340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking the most common 500 labels\n",
        "from collections import Counter\n",
        "\n",
        "Counter = Counter(train_labels_text)\n",
        "most_occur = Counter.most_common(500)\n",
        "classes = [x[0] for x in most_occur]\n",
        "class_to_index = dict((c,i) for i, c in enumerate(classes))\n",
        "index_to_class = dict((i, c) for i, c in enumerate(classes))\n",
        "names_to_ids = lambda labels: np.array([class_to_index.get(x) for x in labels])\n",
        "\n",
        "## Convert the train labels to corresponding int values\n",
        "train_labels = names_to_ids(train_labels_text)\n",
        "val_labels = names_to_ids(val_labels_text)"
      ],
      "metadata": {
        "id": "Na6uZapjIRzU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional class \"unknown\" is defined to accomodate unknown classes\n",
        "\n",
        "class_to_index[\"unknown\"] = len(class_to_index)-1\n",
        "index_to_class[len(class_to_index)-1] = \"unknown\"\n",
        "\n",
        "val_labels[val_labels==None] = len(class_to_index)-1\n",
        "train_labels[train_labels==None] = len(class_to_index)-1"
      ],
      "metadata": {
        "id": "PCuKakvtISyo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create our Text Vectorizer to index our vocabulary based on the train samples \n",
        "from keras.layers import TextVectorization\n",
        "import tensorflow as tf\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=10000, output_sequence_length=100)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_questions).batch(128) ## Read batches of 128 samples\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "EQG_wyPrhd7y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a map to get the unique list of the vocabulary\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "metadata": {
        "id": "72t4PPLMhf_n"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare vectorized train, val and test data\n",
        "\n",
        "x_train_questions = vectorizer(np.array([[s] for s in train_questions])).numpy()\n",
        "x_val_questions = vectorizer(np.array([[s] for s in val_questions])).numpy()\n",
        "x_test_questions = vectorizer(np.array([[s] for s in test_questions])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)"
      ],
      "metadata": {
        "id": "5D0dp2w4hiyQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_questions[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xfSDQ1xmhk5h",
        "outputId": "84167d9e-b668-4043-f132-5f07663e0356"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  3,   2,   5,   7,   6,   5, 152,   9,   4,  37,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing image data\n",
        "import cv2\n",
        "from skimage import io\n",
        "\n",
        "def generate_image_dataset(urls):\n",
        "  print(len(urls))\n",
        "  image_data = []\n",
        "  for i, image_name in enumerate(urls):\n",
        "    image_url = img_dir + image_name\n",
        "    image = io.imread(image_url)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image/255.0\n",
        "    image_data.append(image)\n",
        "    print('\\r', i, end='')\n",
        "  return image_data\n",
        "\n",
        "x_train_images = generate_image_dataset(train_images)\n",
        "x_val_images = generate_image_dataset(val_images)\n",
        "x_test_images = generate_image_dataset(test_images)\n",
        "print(len(x_train_images), len(x_val_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ez31uS-eIT1o",
        "outputId": "a89b126e-4f43-4423-9859-953e581e91b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "621\n",
            " 620131\n",
            " 130320\n",
            " 319621 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensor\n",
        "import tensorflow as tf\n",
        "\n",
        "x_train_imgs = tf.convert_to_tensor(np.array(x_train_images), dtype=tf.float32)\n",
        "x_val_imgs = tf.convert_to_tensor(np.array(x_val_images), dtype=tf.float32)\n",
        "x_test_imgs = tf.convert_to_tensor(np.array(x_test_images), dtype=tf.float32)\n",
        "y_train = tf.convert_to_tensor(np.array(y_train), dtype=tf.float32)\n",
        "y_val = tf.convert_to_tensor(np.array(y_val), dtype=tf.float32)"
      ],
      "metadata": {
        "id": "WkhvC3xFIU8U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EgYIl3LKda73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Download and unzip the Stanford GloVe model (pretrained word embeddings)\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "AsEB_Ui0i-mD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6a10e17d-efac-4537-8261-99e5c318995b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-31 20:34:16--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-03-31 20:34:16--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-03-31 20:34:16--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 40s  \n",
            "\n",
            "2022-03-31 20:36:55 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Read the embeddings in the pretrained model (we are using the 100D version of GloVe)\n",
        "import os\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "id": "rhegfoDojC1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b6e56bf8-ec31-4d50-fa7f-e0a263358936"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create \"embedding_matrix\" to index our vocabulary using the GloVe model \n",
        "num_tokens = len(voc) \n",
        "embedding_dim = 100 ## 100 dimensions\n",
        "hits = 0 ## number of words that were found in the pretrained model\n",
        "misses = 0 ## number of words that were missing in the pretrained model\n",
        "\n",
        "# Prepare embedding matrix for our word list\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "id": "TMqsXsSljc_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "866e5214-e053-4092-8245-4fc3ba84f1a9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 537 words (10 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define our embedding layer for the training model \n",
        "## We load our embedding_matrix as the initializer and set trainable to False to avoid retraining this layer\n",
        "\n",
        "from keras.layers import Embedding, Concatenate\n",
        "from keras.initializers import Constant\n",
        "\n",
        "embedding_layer = Embedding(num_tokens, embedding_dim,\n",
        "                            embeddings_initializer= Constant(embedding_matrix), \n",
        "                            trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "yBOhlJ89jrtL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate image features from pretrained VGG16 trained on Imagenet\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "l2_value = l2(0.00001)\n",
        "\n",
        "def image_model():\n",
        "  image_input = Input(shape=(224,224,3), dtype=\"float32\")\n",
        "  vgg = VGG16()\n",
        "  x = vgg(image_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  return image_input, x\n",
        "\n",
        "def question_model(dropout_rate=0.2):\n",
        "  int_sequences_input = Input(shape=(None,), dtype=\"float32\")\n",
        "  embedded_sequences = embedding_layer(int_sequences_input)\n",
        "  x = layers.Bidirectional(layers.LSTM(20, return_sequences=True))(embedded_sequences)\n",
        "  x = Dropout(dropout_rate)(x)\n",
        "  x = layers.Bidirectional(layers.LSTM(20))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = layers.Dense(1000, activation=\"relu\", kernel_regularizer=l2_value)(x)\n",
        "  preds = BatchNormalization()(x)\n",
        "  # model = Model(int_sequences_input, preds)\n",
        "  return int_sequences_input, preds"
      ],
      "metadata": {
        "id": "V8pQkvy4iGzy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate image features from pretrained VGG16 trained on Imagenet\n",
        "\n",
        "from keras import layers, Input, Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM, Flatten, Embedding, Multiply, Conv2D, MaxPool2D, Embedding\n",
        "import keras,os\n",
        "import numpy as np\n",
        "from keras.initializers import Constant\n",
        "\n",
        "def VQA_model(dropout_rate=0.2, num_classes=500, num_layers=4):\n",
        "    img_input, img_output = image_model()\n",
        "    lstm_input, lstm_output = question_model()\n",
        "    print(\"Merging final model...\")\n",
        "    x = tf.keras.layers.Concatenate(axis=1)([img_output, lstm_output])\n",
        "    # print(x)\n",
        "    x = Dense(1000, activation='relu', kernel_regularizer=l2_value)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(1000, activation='relu', kernel_regularizer=l2_value)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(1000, activation='relu', kernel_regularizer=l2_value)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    if num_layers > 4:\n",
        "      x = Dense(1000, activation='relu', kernel_regularizer=l2_value)(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    preds = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model((img_input, lstm_input), preds)\n",
        "    # print(model.summary())\n",
        "    return model"
      ],
      "metadata": {
        "id": "B3J9cLn2IdMc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vqa_model = VQA_model(dropout_rate=do_value, num_layers=num_layer)\n",
        "# # opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# vqa_model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy',\n",
        "#                   metrics=['accuracy'])\n",
        "\n",
        "# vqa_model.fit((x_train_imgs, x_train_questions), y_train, epochs=6,\n",
        "#               batch_size=5, validation_data=((x_val_imgs, x_val_questions),\n",
        "#                                               y_val))"
      ],
      "metadata": {
        "id": "HGXi84Y7atIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "dropout_values = [0.2, 0.3]\n",
        "num_layers = [4, 5]\n",
        "\n",
        "for do_value in dropout_values:\n",
        "  for num_layer in num_layers:\n",
        "\n",
        "    print(f\"Model: Dropout value {do_value}, Number of Layers {num_layer}\")\n",
        "\n",
        "    vqa_model = VQA_model(dropout_rate=do_value, num_layers=num_layer)\n",
        "    # opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "    vqa_model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "    \n",
        "    vqa_model.fit((x_train_imgs, x_train_questions), y_train, epochs=6,\n",
        "                  batch_size=20, validation_data=((x_val_imgs, x_val_questions),\n",
        "                                                  y_val))"
      ],
      "metadata": {
        "id": "Z6AkJ_mjI5Ti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "014b268f-1930-4d63-80f4-d46b5eff3699"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Dropout value 0.2, Number of Layers 4\n",
            "Merging final model...\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 19s 388ms/step - loss: 6.6623 - accuracy: 0.0515 - val_loss: 6.1865 - val_accuracy: 0.0534\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 11s 342ms/step - loss: 5.7878 - accuracy: 0.0821 - val_loss: 6.2228 - val_accuracy: 0.0534\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 11s 344ms/step - loss: 5.1314 - accuracy: 0.1127 - val_loss: 6.1577 - val_accuracy: 0.0763\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 11s 345ms/step - loss: 4.7555 - accuracy: 0.0821 - val_loss: 6.2808 - val_accuracy: 0.0763\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 11s 347ms/step - loss: 4.4020 - accuracy: 0.1304 - val_loss: 6.4704 - val_accuracy: 0.0763\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 11s 348ms/step - loss: 4.1684 - accuracy: 0.1546 - val_loss: 6.5871 - val_accuracy: 0.0763\n",
            "Model: Dropout value 0.2, Number of Layers 5\n",
            "Merging final model...\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 20s 395ms/step - loss: 6.7729 - accuracy: 0.0386 - val_loss: 6.1014 - val_accuracy: 0.0458\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 11s 349ms/step - loss: 5.8558 - accuracy: 0.0692 - val_loss: 5.7489 - val_accuracy: 0.0763\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 11s 350ms/step - loss: 5.2218 - accuracy: 0.0789 - val_loss: 5.9069 - val_accuracy: 0.0458\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 11s 352ms/step - loss: 4.7904 - accuracy: 0.0837 - val_loss: 6.1176 - val_accuracy: 0.0763\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 11s 353ms/step - loss: 4.4206 - accuracy: 0.1417 - val_loss: 6.2259 - val_accuracy: 0.0840\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 11s 353ms/step - loss: 4.1702 - accuracy: 0.1498 - val_loss: 6.2792 - val_accuracy: 0.0916\n",
            "Model: Dropout value 0.3, Number of Layers 4\n",
            "Merging final model...\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 19s 395ms/step - loss: 6.9521 - accuracy: 0.0225 - val_loss: 6.1484 - val_accuracy: 0.0840\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 11s 348ms/step - loss: 6.1031 - accuracy: 0.0451 - val_loss: 6.2902 - val_accuracy: 0.0305\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 11s 350ms/step - loss: 5.4522 - accuracy: 0.0741 - val_loss: 6.3189 - val_accuracy: 0.0687\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 11s 352ms/step - loss: 5.0522 - accuracy: 0.1127 - val_loss: 6.7387 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 11s 353ms/step - loss: 4.6392 - accuracy: 0.1240 - val_loss: 6.8187 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 11s 353ms/step - loss: 4.2718 - accuracy: 0.1337 - val_loss: 6.9627 - val_accuracy: 0.0000e+00\n",
            "Model: Dropout value 0.3, Number of Layers 5\n",
            "Merging final model...\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 20s 418ms/step - loss: 6.7841 - accuracy: 0.0258 - val_loss: 6.2127 - val_accuracy: 0.0763\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 12s 372ms/step - loss: 5.9980 - accuracy: 0.0596 - val_loss: 6.2252 - val_accuracy: 0.0763\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 12s 375ms/step - loss: 5.5623 - accuracy: 0.0902 - val_loss: 6.4000 - val_accuracy: 0.0458\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 12s 375ms/step - loss: 5.1704 - accuracy: 0.0950 - val_loss: 6.4292 - val_accuracy: 0.0763\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 12s 378ms/step - loss: 4.9320 - accuracy: 0.0837 - val_loss: 6.7361 - val_accuracy: 0.0687\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 12s 377ms/step - loss: 4.6688 - accuracy: 0.1063 - val_loss: 6.9367 - val_accuracy: 0.0687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for input in range(len(x_test_imgs)):\n",
        "  print('\\r', input, end='')\n",
        "\n",
        "  x_im_in = np.reshape(x_test_imgs[input], (1, 224, 224, 3))\n",
        "  x_qu_in = np.reshape(x_test_questions[input], (1, 100))\n",
        "  test_output = fc_model.predict((x_im_in, x_qu_in))\n",
        "  predictions.append(np.argmax(test_output))"
      ],
      "metadata": {
        "id": "00fbZweck0v6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}